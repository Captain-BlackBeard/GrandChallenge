\documentclass{sig-alternate}

\usepackage{color}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{ifpdf}
\usepackage{graphicx}
\usepackage[table]{xcolor}
\usepackage{microtype}

\clubpenalty=10000
\widowpenalty=10000

\setlength{\paperheight}{11in}
\setlength{\paperwidth}{8.5in}
\usepackage[
pass,% keep layout unchanged 
% showframe,% show the layout
]{geometry}

\usepackage{listings}
\lstset{	basicstyle=\normalsize, 
			numbers=left, 
			xleftmargin=2em,
			frame=none,
			framexleftmargin=1.5em,
			numberstyle=\tiny, 
			tabsize=3, 
			language={Java}, 
			escapeinside={/*@}{@*/},
			showstringspaces=false,
			commentstyle=\color[cmyk]{0.3,0.3,0.3,0.3},
			stringstyle=\color[cmyk]{0.92,0,0.95,0.40},
			keywordstyle=\color{blue}\bfseries,
			showspaces=false, 
			showtabs=false}


\newcommand{\TITLE}{The DEBS 2016 Grand Challenge}
\newcommand{\KEYWORDS}{event processing, streaming, social network, graph}
\newcommand{\VG}{Vincenzo Gulisano}
\newcommand{\VGEMAIL}{{\normalsize vincenzo.gulisano@chalmers.se}}
\newcommand{\ZJ}{Zbigniew Jerzak}
\newcommand{\ZJEMAIL}{{\normalsize zbigniew.jerzak@sap.com}}
\newcommand{\SV}{Spyros Voulgaris}
\newcommand{\SVEMAIL}{{\normalsize spyros@cs.vu.nl}}
\newcommand{\HZ}{Holger Ziekow}
\newcommand{\HZEMAIL}{{\normalsize zie@hs-furtwangen.de}}


\newcommand{\VGADDR}[1]{	\affaddr{Chalmers University of Technology}\\%
							\affaddr{H\"{o}rsalsv\"{a}gen 11}\\%	
							\affaddr{41296 Gothenburg, Sweden}\\%
							\email{#1}}							
\newcommand{\ZJADDR}[1]{	\affaddr{SAP SE}\\%
							\affaddr{M\"{u}nzstra{\ss}e 15}\\%
							\affaddr{10178 Berlin, Germany}\\%
							\email{#1}}
\newcommand{\SVADDR}[1]{	\affaddr{Vrije Universiteit Amsterdam}\\%
							\affaddr{De Boelelaan 1081A}\\%	
							\affaddr{1081HV Amsterdam, The Netherlands}\\%
							\email{#1}}							
\newcommand{\HZADDR}[1]{	\affaddr{Hochschule Furtwangen}\\%
							\affaddr{Robert-Gerwig-Platz 1}\\%	
							\affaddr{78120 Furtwangen, Germany}\\%
							\email{#1}}							

\ifpdf
	\usepackage[pdftex,%
					plainpages=false,%
					pdfpagelabels=false,
					bookmarksnumbered,%
					colorlinks=true,%
					linkcolor=blue,%
					citecolor=blue,%
					unicode=true]{hyperref} 
	\usepackage{pdfpages}
	\usepackage[all]{hypcap}
	\hypersetup{%
		pdftitle={\TITLE},
		pdfauthor={\VG, \ZJ, \SV, \HZ},
		pdfsubject={\TITLE},
		pdfkeywords={\KEYWORDS},
		bookmarksopen=false,
		unicode=true,
		colorlinks=true,
		hypertexnames=false}
\else
	\usepackage[dvipdfm,%
					pdftitle={\TITLE},
					pdfauthor={\VG, \ZJ, \SV, \HZ},
					pdfsubject={\TITLE},
					pdfkeywords={\KEYWORDS},
					bookmarks=true,%
					pdfpagelabels=false,%
					colorlinks=true,%
					linkcolor=blue,%
					citecolor=blue]{hyperref}
\fi

\begin{document}
	
  \newfont{\mycrnotice}{ptmr8t at 7pt}
  \newfont{\myconfname}{ptmri8t at 7pt}
  \let\crnotice\mycrnotice%
  \let\confname\myconfname%
  
  \permission{Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org.}
  \conferenceinfo{DEBS'15,} {June 29 -- July 3, 2015, OSLO, Norway.}
  \copyrightetc{Copyright 2015 ACM \the\acmcopyr}
  \crdata{978-1-4503-3286-6/15/06...\$15.00.\\ http://dx.doi.org/10.1145/2675743.2772598}

\title{\TITLE}

\numberofauthors{4}
\author{
\alignauthor	\VG\\
					\VGADDR{\VGEMAIL}
\alignauthor	\ZJ\\
					\ZJADDR{\ZJEMAIL}
\alignauthor	\SV\\
					\SVADDR{\SVEMAIL}
\and
\alignauthor	\HZ\\
					\HZADDR{\HZEMAIL}
}

\date{\today}
\maketitle

\begin{abstract}
Pending...
\end{abstract}


\category{C.2.4}{Computer-Communication Networks}{Distributed Systems}[Distributed Applications]
\terms{Algorithms, Design}
\keywords{\KEYWORDS} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Intro                       %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:introduction}
The ACM DEBS 2016 Grand Challenge is the sixth in a series~\cite{jerzak2012debs, mutschler2013debs, jerzak2014debs, jerzak2015debs} of challenges which seek to provide a common ground and uniform evaluation criteria for a competition aimed at both research and industrial event-based systems. The goal of the 2016 DEBS Grand Challenge competition is to evaluate event-based systems for real-time analytics over high volume data streams in the context of graph models.

The underlying scenario addresses the analysis metrics for a dynamic (evolving) social-network graph. Specifically, the 2016 Grand Challenge targets following problems: (1) identification of the posts that currently trigger the most activity in the social network, and (2) identification of large communities that are currently involved in a topic. The corresponding queries require continuous analysis of a dynamic graph under the consideration of multiple streams that reflect updates to the graph.

The data for the DEBS 2016 Grand Challenge is based on the dataset provided together with the LDBC Social Network Benchmark~\cite{erling2015social}. DEBS 2016 Grand Challenge takes up the general scenario from the 2014 SIGMOD Programming Contest~\cite{DBLP:conf/sigmod/2014}, however, in contrasts to the SIGMOD contest, it explicitly focuses on processing streaming data and thus dynamic graphs. Details about the data, queries for the Grand Challenge, and information about evaluation are provided below.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Data                       %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data}
\label{sec:data}
The data for the 2016 Grand Challenge is organized in four separate streams, each provided as a text file. The first input stream indicates when two users enter a "friendship" relationship -- see Table~\ref{table:friend} and Listing~\ref{code:friend}. The first input stream file name is $friendships.dat$.

\definecolor{lgray}{gray}{0.94}
\definecolor{llgray}{gray}{0.99}

\rowcolors{1}{lgray}{llgray}
\begin{table}[ht]
	\caption{The set of attributes used in the $friendships.dat$ input file}
	\centering 
	\begin{tabular}{r p{5.2cm}}
		\toprule
		Attribute		&	 Description\\
		\midrule
		ts			&	timestamp indicating when a friendship was established\\[2ex]
		user\_id\_1	&	id of one of the users\\[2ex]
		user\_id\_2	&	id of the other user\\[2ex]		
		\bottomrule 
	\end{tabular}
	\label{table:friend}
\end{table}



\lstset{}
\begin{lstlisting}[float=ht,caption={First line from the $friendships.dat$ file -- one attribute per line of listing},label={code:friend}]
XXX
YYY
ZZZ
PLEASE ADD ACTUAL DATA HERE
\end{lstlisting}	

The second input stream indicates when a users creates a new post -- see Table~\ref{table:post} and Listing~\ref{code:post}. The second input stream file name is $posts.dat$.

\rowcolors{1}{lgray}{llgray}
\begin{table}[ht]
	\caption{The set of attributes used in the $posts.dat$ input file}
	\centering 
	\begin{tabular}{r p{5.2cm}}
		\toprule
		Attribute		&	 Description\\
		\midrule
		ts			&	timestamp indicating when a post was created\\[2ex]
		post\_id	&	unique id of the post\\[2ex]
		user\_id	&	unique id of the user who created the post\\[2ex]		
		post		& 	string containing the post's content\\[2ex]		
		user		&   string containing the user name of the post creator\\[2ex]
		\bottomrule 
	\end{tabular}
	\label{table:post}
\end{table}



\lstset{}
\begin{lstlisting}[float=ht,caption={First line from the $posts.dat$ file -- one attribute per line of listing},label={code:post}]
XXX
YYY
ZZZ
PLEASE ADD ACTUAL DATA HERE
\end{lstlisting}

The third input stream indicates when a users commnets on a post -- see Table~\ref{table:comment} and Listing~\ref{code:comment}. The third input stream file name is $comments.dat$.

\rowcolors{1}{lgray}{llgray}
\begin{table}[ht]
	\caption{The set of attributes used in the $comments.dat$ input file}
	\centering 
	\begin{tabular}{r p{5.2cm}}
		\toprule
		Attribute		&	 Description\\
		\midrule
		ts			&	timestamp indicating when a comment was created\\[2ex]
		comment\_id	&	unique id of the comment\\[2ex]
		user\_id	&	unique id of the user who created the comment\\[2ex]		
		comment		& 	string containing the comment's content\\[2ex]		
		user		&   string containing the user name of the comment creator\\[2ex]
		comment\_replied		&   id of the comment being commented (-1 if this is a comment to a post)\\[2ex]
		post\_commented		&   id of the post being commented (-1 if this is a comment to a comment)\\[2ex]
		\bottomrule 
	\end{tabular}
	\label{table:comment}
\end{table}



\lstset{}
\begin{lstlisting}[float=ht,caption={First line from the $comments.dat$ file -- one attribute per line of listing},label={code:comment}]
XXX
YYY
ZZZ
PLEASE ADD ACTUAL DATA HERE
\end{lstlisting}

The fourth input stream indicates when a users likes a comment -- see Table~\ref{table:like} and Listing~\ref{code:like}. The fourth input stream file name is $likes.dat$.

\rowcolors{1}{lgray}{llgray}
\begin{table}[ht]
	\caption{The set of attributes used in the $likes.dat$ input file}
	\centering 
	\begin{tabular}{r p{5.2cm}}
		\toprule
		Attribute		&	 Description\\
		\midrule
		ts			&	timestamp indicating when user liked a comment\\[2ex]
		user\_id	&	unique id of the user who liked the comment\\[2ex]		
		comment\_id	& 	unique id of the comment that was liked\\[2ex]		
		\bottomrule 
	\end{tabular}
	\label{table:like}
\end{table}



\lstset{}
\begin{lstlisting}[float=ht,caption={First line from the $comments.dat$ file -- one attribute per line of listing},label={code:like}]
XXX
YYY
ZZZ
PLEASE ADD ACTUAL DATA HERE
\end{lstlisting}

Each of the data files is sorted chronologically based on the timestamp ($ts$) attribute. Please note that the logical time of the processing engine is advanced through the timestamps in the respective tuples in the input streams. Specifically, the logical clocks of different queries may be advancing independently from each other. Input tuples with the same time stamp must be processed in the order of arrival.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Query 1                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Three Top Scoring Posts Query}
\label{sec:query1}
The goal of the first query is to compute the top three scoring active posts, producing an updated result every time the list changes. The total score of an active post $P$ is computed as the sum of its own score plus the score of all its related comments. Active posts having the same total score should be ranked based on their timestamps -- in descending order. And if their timestamps are also identical, they should be ranked based on the timestamps of their last received related comments -- in descending order. A comment $C$ is related to a post $P$ if it is a direct reply to $P$ or if the chain of $C$'s preceding messages links back to $P$.

Each new post has an initial own score of 10 which decreases by 1 each time another 24 hours elapse since the post's creation. Each new comment's score is also initially set to 10 and decreases by 1 in the same way, i.e., every 24 hours since the comment's creation. Both post and comment scores are non-negative numbers, that is, they cannot drop below zero. A post is considered no longer active (that is, no longer part of the present and future analysis) as soon as its total score reaches zero, even if it receives additional comments in the future. The output format for the result stream is shown in Table~\ref{table:query1}. 

\rowcolors{1}{lgray}{llgray}
\begin{table}[ht]
	\caption{The output format for the first query.}
	\centering 
	\begin{tabular}{r p{5.2cm}}
		\toprule
		Attribute		&	 Description\\
		\midrule
		ts			&	the timestamp of the event that triggers a change in the top-3 scoring active posts appearing in the rest of the tuple\\[2ex]
		topX\_post\_id	&	the unique id of the top-X post\\[2ex]		
		topX\_post\_user	& 	 author of top-X post\\[2ex]		
		topX\_post\_commenters & number of unique users commenting on the top-X post, excluding the post author\\[2ex]
		\bottomrule 
	\end{tabular}
	\label{table:query1}
\end{table}

Results must be sorted by their timestamp ($ts$) field. For updates caused by a timeout event, e.g., a post's score dropping every 24 hours, $ts$ is the logical time of the event's generation, plus the logical time duration of the time window. For example, if a comment's expiration should produce some output at logical time 10:00, the logical clock goes past 10:00 only once the first tuple with a later timestamp is processed.

Please note that furthermore, input tuples with the same time stamp must be processed in the order of arrival. For example: if a post $A$ expires at time $X$ and another post $B$ arrives at time $X$, followed by a comment $C$ (for post $A$) arriving at the same time $X$, then the post $A$ will expire. The reason for this is that post $B$ will be processed before comment $C$. Processing of post $B$ will trigger the expiration of the old post $A$. The subsequent comment $C$ (for post $A$) will not have a post $A$ to reference.

Specifically, when processing a new input tuple, processing steps should be performed in this order: (1) decrease the score of all previous posts (given the semantics of the query) (2) increase score of post related to the input tuple, (3) decrease score of posts expiring precisely on this timestamp, if any, and (4) discard posts with score equal to zero. Such a post would, thus, survive the transient state. However, a post whose score reached zaero at a timestamp earlier than the current input tuple, will not survive, even if the processing of that timeout happens to be triggered by the current input tuple. 

The character ,,--'' (a minus sign without the quotation marks) should be used for each of the fields (topX\_post\_id, topX\_post\_user, topX\_post\_commenters) of any of the top three positions that has not been defined. The logical time of the query advances based on the timestamps of the input tuples, not the system clock. Listing~\ref{code:query1} shows the example output for the first query.

\begin{lstlisting}[float=ht,caption={Output example for the three top scoring posts query},label={code:query1}]
2010-09-19 12:33:01.923+0000,/*@\\@*/  25769805561,Karl Fischer,115,10,/*@\\@*/  25769805933,Chong Liu,83,4,/*@\\@*/  -,-,-,-
2010-10-09 21:55:24.943+0000,/*@\\@*/  34359739095,Karl Fischer,58,7,/*@\\@*/  34359740594,Paul Becker,40,2,/*@\\@*/  34359740220,Chong Zhang,10,0
2010-12-27 22:11:54.953+0000,/*@\\@*/  42949673675,Anson Chen,127,12,/*@\\@*/  42949673684,Yahya Abdallahi,69,8,/*@\\@*/  42949674571,Alim Guliyev,10,0
\end{lstlisting}

An update to the result stream must be produced whenever any of the top three comments changes. Specifically, if any of the scores changes, but the comments remain the same, no output must be produced. When the end of the input stream is reached (defined as EOF value) all outstanding tuples (in the window) for each query must be processed and results must be output. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Query 2                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Community Interest Query}
\label{sec:query2}
The second query addresses the change of interests with large communities. This query represents a version of query type 2 from the 2014 SIGMOD Programming contest. Unlike in the SIGMOD problem, the version for the DEBS Grand Challenge focuses on the dynamic change of query results over time, i.e., calls for a continuous evaluation of the results. 

The goal of the query is given an integer $k$ and a duration $d$ (in seconds), to find the $k$ comments with the largest range. A range of a comment is defined as the size of the largest connected component in the graph defined by:  
\begin{enumerate}
		\item users who have liked that comment -- see files $likes.dat$ and $comments.dat$
		\item the comment was created not more than $d$ seconds ago
		\item users who liked that comment who know each other -- see $friendships.dat$
\end{enumerate}	
Specifically, the size of a component is determined by group members who: (1) all like the comment in question, (2) are all friends with each other, i.e., they form a clique.

The output of the second query includes a single timestamp $ts$ and exactly $k$ strings per line. The timestamp and the strings should be separated by commas. The $k$ strings represent comments, ordered by range from largest to smallest, with ties broken by ascending lexicographical order. The $k$ strings and the corresponding timestamp must be printed only when an input event triggers a change of the output. If less than $k$ strings can be determined, the character ,,--'' (a minus sign without the quotation marks) should be printed in place of each missing string. The output format for the result stream is shown in Table~\ref{table:query2}. 

\rowcolors{1}{lgray}{llgray}
\begin{table}[ht]
	\caption{The output format for the second query.}
	\centering 
	\begin{tabular}{r p{5.2cm}}
		\toprule
		Attribute		&	 Description\\
		\midrule
		ts			&	the timestamp of the event that triggers a change in the output\\[2ex]
		comment\_X	&	top $k$ comments ordered by range\\[2ex]		
		\bottomrule 
	\end{tabular}
	\label{table:query2}
\end{table}

The field $ts$ corresponds to the timestamp of the input data item that triggered an output update. For instance, a new friendship relation may change the size of a community with a shared interest and hence may change the $k$ strings. The timestamp of the event denoting the added friendship relation is then the timestamp $ts$ for that line's output. Also, the output must be updated when the results change due to the progress of time, e.g., when a comment is older that $d$. Specifically, if the update is triggered by an event leaving a time window at $t2$, i.e., $t2$ $=$ timestamp of the event $+$ window size, the timestamp for the update is $t2$. As in the first query (see Section~\ref{sec:query1}), timestamps refer to the logical time of the input data streams, rather than on the system clock.

Listing~\ref{code:query2} shows the example output for the first query with a $k$ value equal to three. 

\begin{lstlisting}[float=ht,caption={Output example for the community interest query},label={code:query2}]
2010-10-28T05:01:31.022+0000,/*@\\@*/  I love strawberries,/*@\\@*/  -,/*@\\@*/  -
2010-10-28T05:01:31.024+0000,/*@\\@*/  I love strawberries,/*@\\@*/  what a day!,/*@\\@*/  -
2010-10-28T05:01:31.027+0000,/*@\\@*/  I love strawberries,/*@\\@*/  what a day!,/*@\\@*/  well done
2010-10-28T05:01:31.032+0000,/*@\\@*/  what a day!,/*@\\@*/  I love strawberries,/*@\\@*/  well done
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Additional Remarks          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Additional Remarks}
For both queries it is assumed that the result is calculated in a streaming fashion - i.e.: (1) solutions must not make use of any pre-calculated information, such as indices and (2) result streams must be updated continuously.

The ranking of the submissions is done using the total duration of the execution and the average delay per stream. Specifically, solutions are ranked (a) by the total execution time as well as (b) by the average latency. The final result is calculated as a sum of average results from both query result streams. The average latency should be computed as the average of each output tuple latency, the latter measured as the difference between the system clock taken when logging an output tuple and the system clock taken when the processing of the input tuple triggering the result starts. The latency measurement always refers to the real time it takes to process a single input tuple. Even when an input tuple triggers an update caused by the timeout of some event, it is the present input tuple's latency that should be measured, which has nothing to do with the logical or real time elapsed since the past event that just timed out.

The final ranking is determined by a score that is the sum of the rank for execution time and the rank for delay. For solutions with the same overall score the solution with the lower execution time will be ranked higher.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% License                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{License}
All solutions submitted to the DEBS 2016 Grand Challenge are open source under the BSD license: \url{https://opensource.org/licenses/BSD-3-Clause}. A solution incorporates concepts, queries, and code developed for the purpose of solving the Grand Challenge. If a solution is developed within the context of, is built on top of, or is using an existing system or solution which is licensed under a different license than BSD, then such an existing solution or system maintains its existing license.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}
The DEBS Grand Challenge Organizing Committee would like to explicitly thank WSO2 (\url{http://wso2.com}) for sponsoring the DEBS 2016 Grand Challenge prize and the LDBC Council (\url{http://www.ldbcouncil.org}) for their help in preparing the test data set.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% References                  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{plain}
\bibliography{debsgc2016}

%\balancecolumns

\end{document}
